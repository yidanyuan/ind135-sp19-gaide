{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import models to be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import multiprocessing\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras import utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import utils\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "import glob \n",
    "import librosa.display\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "path = 'call/'\n",
    "filenames = []\n",
    "label = []\n",
    "for filename in glob.glob(os.path.join(path, '*.wav')):\n",
    "    filenames.append(filename)\n",
    "    if \"english\" in filename:\n",
    "        label.append(1)\n",
    "    if \"mandarin\" in filename:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = pd.DataFrame({'feature': filenames, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we extract mfcc feature from data\n",
    "def extract_feature(file_name):\n",
    "    try:\n",
    "        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None, None\n",
    "    return (mfccs)\n",
    "\n",
    "feature = []\n",
    "for i in range(len(filenames)):\n",
    "    feature.append(extract_feature(filenames[i]))\n",
    "     \n",
    "\n",
    "temp = pd.DataFrame({'feature': feature, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for building model and split data into train data and validation data\n",
    "\n",
    "X = np.array(temp.feature.tolist())\n",
    "y = np.array(temp.label.tolist())\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y = utils.to_categorical(lb.fit_transform(y))\n",
    "\n",
    "cut_x = round(0.8*len(X))\n",
    "cut_y = round(0.8*len(y))\n",
    "\n",
    "valX = X[len(X) - cut_x:]\n",
    "valY = y[len(y) - cut_y:]\n",
    "\n",
    "\n",
    "X = X[0:len(X) - cut_x]\n",
    "y = y[0:len(y) - cut_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2683: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2550: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "labels = y.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 151 samples, validate on 605 samples\n",
      "Epoch 1/5\n",
      "151/151 [==============================] - 0s - loss: 4.5054 - acc: 0.7152 - val_loss: 2.3977 - val_acc: 0.8512\n",
      "Epoch 2/5\n",
      "151/151 [==============================] - 0s - loss: 4.4832 - acc: 0.7219 - val_loss: 2.3977 - val_acc: 0.8512\n",
      "Epoch 3/5\n",
      "151/151 [==============================] - 0s - loss: 4.4832 - acc: 0.7219 - val_loss: 2.3977 - val_acc: 0.8512\n",
      "Epoch 4/5\n",
      "151/151 [==============================] - 0s - loss: 4.4832 - acc: 0.7219 - val_loss: 2.3977 - val_acc: 0.8512\n",
      "Epoch 5/5\n",
      "151/151 [==============================] - 0s - loss: 4.4832 - acc: 0.7219 - val_loss: 2.3977 - val_acc: 0.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ce7a630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=5, validation_data=(valX, valY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('call.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
